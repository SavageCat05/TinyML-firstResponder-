{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cb09b16",
   "metadata": {},
   "source": [
    "# TinyML Emergency Intent Detection — Data Collection & Processing Pipeline\n",
    "\n",
    "**Version**: 1.0 (Frozen for reproducibility)\n",
    "**Target**: On-device emergency intent classification from raw audio\n",
    "**Runtime**: Kaggle Notebook (all data from `/kaggle/input/`); also supports local workspace paths\n",
    "\n",
    "---\n",
    "\n",
    "## Pipeline Overview\n",
    "\n",
    "| Stage | Purpose |\n",
    "|-------|---------|\n",
    "| **1. Configuration** | Fix every hyperparameter, path, and label mapping once |\n",
    "| **2. Dataset Adapters** | Per-source logic that emits `(file_path, intent_label)` tuples |\n",
    "| **3. Audio Canonicalization** | Load → mono → 16 kHz → DC-offset removal → RMS normalisation |\n",
    "| **4. Sliding-Window Segmentation** | 2.0 s windows, 1.0 s hop, per-window silence rejection |\n",
    "| **5. Safety-Critical Filtering** | Clip detection, energy outliers, ambiguity rejection |\n",
    "| **6. Unified Assembly** | Deterministic shuffle, class-balanced sampling, manifest CSV |\n",
    "| **7. Verification** | Automated integrity assertions + audit trail |\n",
    "\n",
    "### Canonical Label Schema\n",
    "\n",
    "| int | label | meaning |\n",
    "|-----|-------|---------|\n",
    "| 0 | `non_emergency` | Calm / neutral / everyday speech |\n",
    "| 1 | `general_distress` | Fear, anger, panic — acoustic distress |\n",
    "| 2 | `threat_keyword` | Explicit threat/help phrases (verbal) |\n",
    "| 3 | `emergency_call` | Real 911 / emergency-call audio |\n",
    "\n",
    "### Audio Contract\n",
    "\n",
    "| Parameter | Value |\n",
    "|-----------|-------|\n",
    "| Sample rate | 16 000 Hz |\n",
    "| Channels | 1 (mono) |\n",
    "| Window length | 2.0 s (32 000 samples) |\n",
    "| Hop length | 1.0 s (16 000 samples) |\n",
    "| Dtype | `float32` (normalised to ±1.0) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae152216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# Stage 1 · Imports & Global Configuration\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "from __future__ import annotations\n",
    "\n",
    "import hashlib, json, math, os, platform, sys, warnings\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from enum import IntEnum\n",
    "from pathlib import Path\n",
    "from typing import Dict, Generator, List, Optional, Tuple\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# ── Deterministic seed (used for all stochastic operations) ──\n",
    "GLOBAL_SEED: int = 42\n",
    "_rng = np.random.default_rng(GLOBAL_SEED)\n",
    "\n",
    "print(f\"Python  : {sys.version}\")\n",
    "print(f\"NumPy   : {np.__version__}\")\n",
    "print(f\"librosa : {librosa.__version__}\")\n",
    "print(f\"pandas  : {pd.__version__}\")\n",
    "print(f\"Platform: {platform.platform()}\")\n",
    "print(f\"Seed    : {GLOBAL_SEED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd590c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# Stage 1 (cont.) · Canonical Labels & Audio Contract\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "\n",
    "class Intent(IntEnum):\n",
    "    \"\"\"Canonical intent labels — the ONLY labels the model will ever see.\"\"\"\n",
    "    NON_EMERGENCY    = 0   # calm / neutral / everyday speech\n",
    "    GENERAL_DISTRESS = 1   # fear, anger, panic — acoustic distress\n",
    "    THREAT_KEYWORD   = 2   # explicit threat / help phrases (verbal)\n",
    "    EMERGENCY_CALL   = 3   # real 911 / emergency-call audio\n",
    "\n",
    "INTENT_NAMES: Dict[int, str] = {i.value: i.name.lower() for i in Intent}\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class AudioContract:\n",
    "    \"\"\"Immutable audio-processing constants — set once, used everywhere.\"\"\"\n",
    "    sr: int            = 16_000          # sample rate (Hz)\n",
    "    window_sec: float  = 2.0             # context window (seconds)\n",
    "    hop_sec: float     = 1.0             # hop between windows (seconds)\n",
    "    rms_floor: float   = 0.005           # silence gate (RMS below → discard)\n",
    "    rms_ceiling: float = 0.90            # clipping gate (peak above → discard)\n",
    "    target_rms: float  = 0.1             # target RMS after normalisation\n",
    "    min_src_dur: float = 0.5             # shortest source file accepted (sec)\n",
    "    max_src_dur: float = 600.0           # longest source file accepted (sec)\n",
    "\n",
    "    # ── derived (computed once) ────────────────────────────────\n",
    "    @property\n",
    "    def window_samples(self) -> int:\n",
    "        return int(self.sr * self.window_sec)           # 32 000\n",
    "\n",
    "    @property\n",
    "    def hop_samples(self) -> int:\n",
    "        return int(self.sr * self.hop_sec)               # 16 000\n",
    "\n",
    "\n",
    "AC = AudioContract()\n",
    "print(f\"Window : {AC.window_sec}s = {AC.window_samples} samples\")\n",
    "print(f\"Hop    : {AC.hop_sec}s = {AC.hop_samples} samples\")\n",
    "print(f\"Labels : {INTENT_NAMES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea33f4cf",
   "metadata": {},
   "source": [
    "## Stage 2 · Dataset Path Registry & Adapter Declarations\n",
    "\n",
    "Every dataset is registered here **once**. The adapter knows:\n",
    "- where files live (Kaggle path + local fallback)\n",
    "- what audio extensions to scan\n",
    "- which canonical `Intent` label to assign and how\n",
    "\n",
    "| Dataset | Source | Files | Default Intent |\n",
    "|---------|--------|-------|----------------|\n",
    "| 911 Recordings | 6-second 911 call clips with CSV metadata | ~707 | `EMERGENCY_CALL` |\n",
    "| RAVDESS | Acted emotional speech (8 emotions × 24 actors) | ~1 440 | mapped per emotion code |\n",
    "| Threat-keyword | Spoken distress phrases (7 categories, EN + HI) | ~360 | `THREAT_KEYWORD` |\n",
    "| Custom SER | Emergency-call emotional speech (18 speakers) | ~316 | `GENERAL_DISTRESS` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e88600b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# Stage 2 · Dataset Path Registry\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# Detect runtime: Kaggle vs local development\n",
    "IS_KAGGLE: bool = Path(\"/kaggle/input\").exists()\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DatasetEntry:\n",
    "    \"\"\"Registry entry for one dataset source.\"\"\"\n",
    "    name: str                          # short identifier\n",
    "    kaggle_root: str                   # absolute path on Kaggle\n",
    "    local_root: str                    # relative path for local dev\n",
    "    audio_exts: Tuple[str, ...] = (\".wav\",)\n",
    "\n",
    "    @property\n",
    "    def root(self) -> Path:\n",
    "        \"\"\"Return whichever root exists in the current environment.\"\"\"\n",
    "        if IS_KAGGLE:\n",
    "            p = Path(self.kaggle_root)\n",
    "        else:\n",
    "            p = Path(__file__).resolve().parent / self.local_root if \"__file__\" in dir() else Path(self.local_root)\n",
    "        return p\n",
    "\n",
    "# ── Registry ─────────────────────────────────────────────────\n",
    "DS_911 = DatasetEntry(\n",
    "    name=\"911_calls\",\n",
    "    kaggle_root=\"/kaggle/input/911-calls-dataset-eda/911_first6sec\",\n",
    "    local_root=\"../datasets/911_recordings/911_first6sec\",\n",
    ")\n",
    "\n",
    "DS_RAVDESS = DatasetEntry(\n",
    "    name=\"ravdess\",\n",
    "    kaggle_root=\"/kaggle/input/ravdess-emotional-speech-audio/audio_speech_actors_01-24\",\n",
    "    # NOTE: We use ONLY the nested copy to avoid duplicates\n",
    "    local_root=\"../datasets/ravdess_emotional_speech_audio/audio_speech_actors_01-24\",\n",
    ")\n",
    "\n",
    "DS_THREAT = DatasetEntry(\n",
    "    name=\"threat_keyword\",\n",
    "    kaggle_root=\"/kaggle/input/threat-detection-audio-dataset/Audio_Dataset3\",\n",
    "    local_root=\"../datasets/threat detection audio dataset/Audio_Dataset3\",\n",
    ")\n",
    "\n",
    "DS_CUSTOM_SER = DatasetEntry(\n",
    "    name=\"custom_ser\",\n",
    "    kaggle_root=\"/kaggle/input/speech-emotion-recognition-emergency/CUSTOM_DATASET\",\n",
    "    local_root=\"../datasets/speech emotional recognition for emergency calls/CUSTOM_DATASET\",\n",
    ")\n",
    "\n",
    "ALL_DATASETS: List[DatasetEntry] = [DS_911, DS_RAVDESS, DS_THREAT, DS_CUSTOM_SER]\n",
    "\n",
    "print(f\"Runtime       : {'Kaggle' if IS_KAGGLE else 'Local'}\")\n",
    "for ds in ALL_DATASETS:\n",
    "    exists = ds.root.exists()\n",
    "    print(f\"  {ds.name:20s} → {ds.root}  {'✓' if exists else '✗ NOT FOUND'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d9c6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# Stage 2 (cont.) · Dataset Adapter Functions\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# Each adapter yields (file_path: Path, intent: Intent) tuples.\n",
    "# Adapters encapsulate ALL dataset-specific logic — label parsing,\n",
    "# filename conventions, metadata lookups, and ambiguity rejection.\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "\n",
    "def _scan_audio(root: Path, exts: Tuple[str, ...] = (\".wav\",)) -> List[Path]:\n",
    "    \"\"\"Recursively collect audio files under *root*, sorted for determinism.\"\"\"\n",
    "    files = []\n",
    "    for ext in exts:\n",
    "        files.extend(root.rglob(f\"*{ext}\"))\n",
    "    return sorted(files)\n",
    "\n",
    "\n",
    "# ── 911 Calls Adapter ────────────────────────────────────────\n",
    "def adapt_911(ds: DatasetEntry) -> Generator[Tuple[Path, Intent], None, None]:\n",
    "    \"\"\"\n",
    "    911-call clips (≈6 s each).\n",
    "    Metadata CSV contains a `false_alarm` column — we use it to reject\n",
    "    prank / non-emergency 911 recordings.  Remaining clips → EMERGENCY_CALL.\n",
    "\n",
    "    Conservative rule:\n",
    "        • false_alarm == 1  → SKIP  (not a real emergency)\n",
    "        • false_alarm == 0  → EMERGENCY_CALL\n",
    "    \"\"\"\n",
    "    csv_path = ds.root / \"911_metadata.csv\"\n",
    "    if csv_path.exists():\n",
    "        meta = pd.read_csv(csv_path)\n",
    "        # Build filename → false_alarm lookup\n",
    "        fa_lookup: Dict[str, float] = {}\n",
    "        for _, row in meta.iterrows():\n",
    "            fname = str(row.get(\"filename\", \"\"))\n",
    "            # filename column has relative path like '911_first6sec/call_2_0.wav'\n",
    "            basename = Path(fname).name\n",
    "            fa_lookup[basename] = float(row.get(\"false_alarm\", 0))\n",
    "    else:\n",
    "        fa_lookup = {}\n",
    "\n",
    "    for fp in _scan_audio(ds.root, ds.audio_exts):\n",
    "        basename = fp.name\n",
    "        # Reject known false-alarm / prank calls\n",
    "        if fa_lookup.get(basename, 0) == 1.0:\n",
    "            continue\n",
    "        yield fp, Intent.EMERGENCY_CALL\n",
    "\n",
    "\n",
    "# ── RAVDESS Adapter ──────────────────────────────────────────\n",
    "# Filename schema: MM-VC-EM-IN-ST-RE-AC.wav\n",
    "#   MM = modality (03 = audio-only)\n",
    "#   VC = vocal channel (01 = speech, 02 = song)\n",
    "#   EM = emotion  (01-08)\n",
    "#   IN = intensity (01 = normal, 02 = strong)\n",
    "#   ST = statement (01 / 02)\n",
    "#   RE = repetition (01 / 02)\n",
    "#   AC = actor (01-24, odd = male, even = female)\n",
    "#\n",
    "# Emotion mapping (conservative):\n",
    "RAVDESS_EMOTION_MAP: Dict[str, Optional[Intent]] = {\n",
    "    \"01\": Intent.NON_EMERGENCY,       # neutral\n",
    "    \"02\": Intent.NON_EMERGENCY,       # calm\n",
    "    \"03\": Intent.NON_EMERGENCY,       # happy\n",
    "    \"04\": None,                        # sad — ambiguous → DROP\n",
    "    \"05\": Intent.GENERAL_DISTRESS,    # angry\n",
    "    \"06\": Intent.GENERAL_DISTRESS,    # fearful\n",
    "    \"07\": None,                        # disgust — ambiguous → DROP\n",
    "    \"08\": None,                        # surprised — ambiguous → DROP\n",
    "}\n",
    "\n",
    "def adapt_ravdess(ds: DatasetEntry) -> Generator[Tuple[Path, Intent], None, None]:\n",
    "    \"\"\"\n",
    "    RAVDESS acted emotional speech.\n",
    "    We use ONLY speech modality (vocal channel 01) and audio-only files.\n",
    "    Ambiguous emotions (sad, disgust, surprised) are DROPPED.\n",
    "    \"\"\"\n",
    "    for fp in _scan_audio(ds.root, ds.audio_exts):\n",
    "        parts = fp.stem.split(\"-\")\n",
    "        if len(parts) != 7:\n",
    "            continue                    # malformed filename → skip\n",
    "\n",
    "        modality, vocal_ch, emotion = parts[0], parts[1], parts[2]\n",
    "\n",
    "        # Accept only audio-only (03) speech (01) files\n",
    "        if modality != \"03\" or vocal_ch != \"01\":\n",
    "            continue\n",
    "\n",
    "        intent = RAVDESS_EMOTION_MAP.get(emotion)\n",
    "        if intent is None:\n",
    "            continue                    # ambiguous emotion → drop\n",
    "\n",
    "        yield fp, intent\n",
    "\n",
    "\n",
    "# ── Threat-Keyword Adapter ───────────────────────────────────\n",
    "# Folder names encode the spoken phrase.  ALL folders represent\n",
    "# explicit distress / threat keywords → THREAT_KEYWORD.\n",
    "THREAT_FOLDER_INTENTS: Dict[str, Intent] = {\n",
    "    \"call police\":         Intent.THREAT_KEYWORD,\n",
    "    \"help me\":             Intent.THREAT_KEYWORD,\n",
    "    \"i need help\":         Intent.THREAT_KEYWORD,\n",
    "    \"madat karo\":          Intent.THREAT_KEYWORD,   # Hindi: \"help me\"\n",
    "    \"mujhe_bachao\":        Intent.THREAT_KEYWORD,   # Hindi: \"save me\"\n",
    "    \"palice call martini\": Intent.THREAT_KEYWORD,   # Hindi: \"call the police\"\n",
    "    \"Sendhelp\":            Intent.THREAT_KEYWORD,\n",
    "}\n",
    "\n",
    "def adapt_threat(ds: DatasetEntry) -> Generator[Tuple[Path, Intent], None, None]:\n",
    "    \"\"\"\n",
    "    Threat-keyword dataset — spoken distress phrases.\n",
    "    Label is determined by the parent folder name.\n",
    "    Files whose parent folder is unknown are DROPPED.\n",
    "    \"\"\"\n",
    "    for fp in _scan_audio(ds.root, ds.audio_exts):\n",
    "        folder = fp.parent.name\n",
    "        intent = THREAT_FOLDER_INTENTS.get(folder)\n",
    "        if intent is None:\n",
    "            continue                    # unknown folder → skip\n",
    "        yield fp, intent\n",
    "\n",
    "\n",
    "# ── Custom SER Adapter ───────────────────────────────────────\n",
    "# Filename schema: EE_SS_CC_DD_RR.wav (emotion_speaker_…)\n",
    "# No external documentation — we label conservatively as GENERAL_DISTRESS\n",
    "# because the dataset is specifically curated for \"emergency call\" emotion.\n",
    "def adapt_custom_ser(ds: DatasetEntry) -> Generator[Tuple[Path, Intent], None, None]:\n",
    "    \"\"\"\n",
    "    Custom emergency-call SER dataset (18 speakers).\n",
    "    All files are emotional speech in an emergency-call context.\n",
    "    Conservative label: GENERAL_DISTRESS (acoustic emotional distress).\n",
    "    \"\"\"\n",
    "    for fp in _scan_audio(ds.root, ds.audio_exts):\n",
    "        yield fp, Intent.GENERAL_DISTRESS\n",
    "\n",
    "\n",
    "# ── Adapter dispatch table ───────────────────────────────────\n",
    "ADAPTERS: Dict[str, callable] = {\n",
    "    \"911_calls\":       adapt_911,\n",
    "    \"ravdess\":         adapt_ravdess,\n",
    "    \"threat_keyword\":  adapt_threat,\n",
    "    \"custom_ser\":      adapt_custom_ser,\n",
    "}\n",
    "\n",
    "print(f\"Adapters registered: {list(ADAPTERS.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673c889e",
   "metadata": {},
   "source": [
    "## Stage 3 · Audio Canonicalization\n",
    "\n",
    "Each source file goes through **one deterministic path**:\n",
    "\n",
    "1. `librosa.load` → mono, 16 kHz, float32\n",
    "2. DC-offset removal (`y -= mean`)\n",
    "3. Duration gate (reject files < 0.5 s or > 600 s)\n",
    "4. RMS normalisation to a fixed target (0.1 RMS)\n",
    "5. Peak-limiting (hard clip at ±1.0 with headroom)\n",
    "\n",
    "The result is a numpy array ready for windowing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec76b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# Stage 3 · Audio Canonicalization Functions\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "\n",
    "def load_canonical(path: Path, ac: AudioContract = AC) -> Optional[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Load an audio file and return a canonicalised float32 numpy array,\n",
    "    or *None* if the file should be rejected.\n",
    "\n",
    "    Steps:\n",
    "        1. librosa.load → mono, target SR, float32\n",
    "        2. DC-offset removal\n",
    "        3. Duration gate\n",
    "        4. RMS normalisation → target_rms\n",
    "        5. Peak-limit to ±1.0\n",
    "    \"\"\"\n",
    "    try:\n",
    "        y, _ = librosa.load(path, sr=ac.sr, mono=True)\n",
    "    except Exception:\n",
    "        return None                     # corrupt / unreadable\n",
    "\n",
    "    # ── duration gate ─────────────────────────────────────────\n",
    "    dur = len(y) / ac.sr\n",
    "    if dur < ac.min_src_dur or dur > ac.max_src_dur:\n",
    "        return None\n",
    "\n",
    "    # ── DC-offset removal ─────────────────────────────────────\n",
    "    y = y - np.mean(y)\n",
    "\n",
    "    # ── RMS check — reject near-silence ───────────────────────\n",
    "    rms = float(np.sqrt(np.mean(y ** 2)))\n",
    "    if rms < ac.rms_floor:\n",
    "        return None\n",
    "\n",
    "    # ── RMS normalisation ─────────────────────────────────────\n",
    "    y = y * (ac.target_rms / rms)\n",
    "\n",
    "    # ── peak-limit (hard clip with headroom) ──────────────────\n",
    "    peak = float(np.max(np.abs(y)))\n",
    "    if peak > 1.0:\n",
    "        y = y / peak                    # bring back into [-1, 1]\n",
    "\n",
    "    return y.astype(np.float32)\n",
    "\n",
    "\n",
    "print(\"✓ load_canonical() ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952284e4",
   "metadata": {},
   "source": [
    "## Stage 4 · Sliding-Window Segmentation\n",
    "\n",
    "Each canonicalised audio array is cut into **2.0 s windows** with a **1.0 s hop**.\n",
    "\n",
    "Per-window quality gates applied:\n",
    "- **Silence gate**: window RMS < `rms_floor` → discard\n",
    "- **Clipping gate**: window peak > `rms_ceiling` → discard\n",
    "- **Zero-crossing rate outlier**: optional, catches digital artefacts\n",
    "\n",
    "Short files (< 2.0 s) are **zero-padded on the right** and accepted only\n",
    "if the non-silent portion ≥ 50 % of the window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923b6fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# Stage 4 · Sliding-Window Segmentation\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "\n",
    "@dataclass\n",
    "class WindowMeta:\n",
    "    \"\"\"Metadata for one extracted audio window.\"\"\"\n",
    "    window_id: str              # globally unique identifier\n",
    "    dataset: str                # source dataset name\n",
    "    source_file: str            # original filename (basename only)\n",
    "    intent: int                 # canonical intent label (int)\n",
    "    intent_name: str            # human-readable label\n",
    "    window_idx: int             # window index within source file\n",
    "    rms: float                  # per-window RMS\n",
    "    peak: float                 # per-window peak absolute value\n",
    "    sha256: str                 # SHA-256 of the float32 bytes\n",
    "\n",
    "\n",
    "def _sha256(arr: np.ndarray) -> str:\n",
    "    \"\"\"Deterministic hash of a numpy array's raw bytes.\"\"\"\n",
    "    return hashlib.sha256(arr.tobytes()).hexdigest()[:16]\n",
    "\n",
    "\n",
    "def window_generator(\n",
    "    y: np.ndarray,\n",
    "    intent: Intent,\n",
    "    dataset_name: str,\n",
    "    source_file: str,\n",
    "    file_idx: int,\n",
    "    ac: AudioContract = AC,\n",
    ") -> Generator[Tuple[np.ndarray, WindowMeta], None, None]:\n",
    "    \"\"\"\n",
    "    Yield (window_array, WindowMeta) tuples from a canonicalised audio array.\n",
    "\n",
    "    Rules:\n",
    "        • Full windows only when len(y) >= window_samples.\n",
    "        • If len(y) < window_samples, zero-pad RIGHT and accept only\n",
    "          if the non-silent portion >= 50 % of window.\n",
    "        • Per-window silence & clipping gates applied.\n",
    "    \"\"\"\n",
    "    W = ac.window_samples\n",
    "    H = ac.hop_samples\n",
    "\n",
    "    # ── Handle short files (< 1 window) → zero-pad ───────────\n",
    "    if len(y) < W:\n",
    "        non_silent_frac = len(y) / W\n",
    "        if non_silent_frac < 0.50:\n",
    "            return                      # too short even after padding\n",
    "        padded = np.zeros(W, dtype=np.float32)\n",
    "        padded[: len(y)] = y\n",
    "        y = padded\n",
    "        # Only yield this one padded window\n",
    "        positions = [0]\n",
    "    else:\n",
    "        positions = list(range(0, len(y) - W + 1, H))\n",
    "\n",
    "    for win_idx, start in enumerate(positions):\n",
    "        w = y[start : start + W]\n",
    "\n",
    "        # ── per-window quality gates ──────────────────────────\n",
    "        rms = float(np.sqrt(np.mean(w ** 2)))\n",
    "        peak = float(np.max(np.abs(w)))\n",
    "\n",
    "        if rms < ac.rms_floor:\n",
    "            continue                    # silence → skip\n",
    "        if peak > ac.rms_ceiling:\n",
    "            continue                    # clipping → skip\n",
    "\n",
    "        wid = f\"{dataset_name}_f{file_idx:05d}_w{win_idx:03d}\"\n",
    "        meta = WindowMeta(\n",
    "            window_id=wid,\n",
    "            dataset=dataset_name,\n",
    "            source_file=source_file,\n",
    "            intent=int(intent),\n",
    "            intent_name=INTENT_NAMES[int(intent)],\n",
    "            window_idx=win_idx,\n",
    "            rms=round(rms, 6),\n",
    "            peak=round(peak, 6),\n",
    "            sha256=_sha256(w),\n",
    "        )\n",
    "        yield w, meta\n",
    "\n",
    "\n",
    "print(\"✓ window_generator() ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14c6f58",
   "metadata": {},
   "source": [
    "## Stage 5 · Full Pipeline Execution\n",
    "\n",
    "For each registered dataset:\n",
    "1. Run its adapter to get `(path, intent)` pairs\n",
    "2. Load & canonicalise each file via `load_canonical()`\n",
    "3. Segment into 2.0 s windows via `window_generator()`\n",
    "4. Collect all windows + metadata into a single list\n",
    "\n",
    "Result: a flat list of `(np.ndarray, WindowMeta)` pairs ready for assembly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189ef228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# Stage 5 · Run All Adapters → Canonicalise → Window\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "\n",
    "all_windows: List[np.ndarray] = []\n",
    "all_meta:    List[WindowMeta] = []\n",
    "\n",
    "# Per-dataset counters for audit\n",
    "audit: Dict[str, Dict[str, int]] = {}\n",
    "\n",
    "for ds in ALL_DATASETS:\n",
    "    adapter_fn = ADAPTERS.get(ds.name)\n",
    "    if adapter_fn is None:\n",
    "        print(f\"⚠ No adapter for {ds.name}, skipping\")\n",
    "        continue\n",
    "    if not ds.root.exists():\n",
    "        print(f\"⚠ Path not found for {ds.name}: {ds.root}\")\n",
    "        continue\n",
    "\n",
    "    ds_stats = {\"files_scanned\": 0, \"files_loaded\": 0,\n",
    "                \"files_rejected\": 0, \"windows_emitted\": 0}\n",
    "\n",
    "    print(f\"\\n{'─'*60}\")\n",
    "    print(f\"Processing: {ds.name}\")\n",
    "    print(f\"  Root: {ds.root}\")\n",
    "\n",
    "    file_idx = 0\n",
    "    for fp, intent in adapter_fn(ds):\n",
    "        ds_stats[\"files_scanned\"] += 1\n",
    "        y = load_canonical(fp, AC)\n",
    "        if y is None:\n",
    "            ds_stats[\"files_rejected\"] += 1\n",
    "            continue\n",
    "        ds_stats[\"files_loaded\"] += 1\n",
    "\n",
    "        win_count_before = len(all_windows)\n",
    "        for w, m in window_generator(y, intent, ds.name, fp.name, file_idx, AC):\n",
    "            all_windows.append(w)\n",
    "            all_meta.append(m)\n",
    "        ds_stats[\"windows_emitted\"] += len(all_windows) - win_count_before\n",
    "        file_idx += 1\n",
    "\n",
    "        # Progress indicator every 100 files\n",
    "        if ds_stats[\"files_scanned\"] % 100 == 0:\n",
    "            print(f\"    … {ds_stats['files_scanned']} files scanned\")\n",
    "\n",
    "    audit[ds.name] = ds_stats\n",
    "    print(f\"  Scanned : {ds_stats['files_scanned']}\")\n",
    "    print(f\"  Loaded  : {ds_stats['files_loaded']}\")\n",
    "    print(f\"  Rejected: {ds_stats['files_rejected']}\")\n",
    "    print(f\"  Windows : {ds_stats['windows_emitted']}\")\n",
    "\n",
    "# ── Summary ───────────────────────────────────────────────────\n",
    "print(f\"\\n{'━'*60}\")\n",
    "print(f\"Total windows collected: {len(all_windows)}\")\n",
    "print(f\"Total metadata records : {len(all_meta)}\")\n",
    "assert len(all_windows) == len(all_meta), \"Window/meta count mismatch!\"\n",
    "print(f\"{'━'*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea2eea8",
   "metadata": {},
   "source": [
    "## Stage 6 · Unified Assembly — Manifest, Shuffle, Balance\n",
    "\n",
    "Build a pandas DataFrame from all collected window metadata, apply:\n",
    "1. **Duplicate-hash rejection** — no two windows share the same SHA-256\n",
    "2. **Deterministic shuffle** — fixed seed for train/val reproducibility\n",
    "3. **Class-distribution report** — expose any severe class imbalance\n",
    "4. **Manifest CSV** — the single source of truth for downstream training\n",
    "\n",
    "> **No class resampling is applied here** — that is the training script's\n",
    "> responsibility.  The manifest records the natural distribution so the\n",
    "> trainer can decide on oversampling / loss weighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48974c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# Stage 6 · Unified Assembly — Build Manifest DataFrame\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "\n",
    "# ── Build DataFrame from WindowMeta records ───────────────────\n",
    "manifest = pd.DataFrame([asdict(m) for m in all_meta])\n",
    "print(f\"Raw manifest rows: {len(manifest)}\")\n",
    "\n",
    "# ── Duplicate detection via SHA-256 ───────────────────────────\n",
    "dup_mask = manifest.duplicated(subset=[\"sha256\"], keep=\"first\")\n",
    "n_dups = int(dup_mask.sum())\n",
    "print(f\"Duplicate windows (by SHA-256): {n_dups}\")\n",
    "manifest = manifest[~dup_mask].reset_index(drop=True)\n",
    "print(f\"After deduplication           : {len(manifest)}\")\n",
    "\n",
    "# ── Remove corresponding audio arrays ─────────────────────────\n",
    "# Build the surviving indices from the original all_meta list\n",
    "surviving_indices = manifest.index.tolist()\n",
    "# Actually, we need to track original indices before reset\n",
    "# Rebuild from scratch — safer:\n",
    "manifest_pre = pd.DataFrame([asdict(m) for m in all_meta])\n",
    "dup_mask2 = manifest_pre.duplicated(subset=[\"sha256\"], keep=\"first\")\n",
    "keep_mask = ~dup_mask2\n",
    "surviving_windows = [all_windows[i] for i in range(len(all_windows)) if keep_mask.iloc[i]]\n",
    "\n",
    "assert len(surviving_windows) == len(manifest), \\\n",
    "    f\"Window/manifest mismatch after dedup: {len(surviving_windows)} vs {len(manifest)}\"\n",
    "\n",
    "# ── Deterministic shuffle ─────────────────────────────────────\n",
    "shuffle_idx = _rng.permutation(len(manifest))\n",
    "manifest = manifest.iloc[shuffle_idx].reset_index(drop=True)\n",
    "surviving_windows = [surviving_windows[i] for i in shuffle_idx]\n",
    "\n",
    "# ── Class distribution report ─────────────────────────────────\n",
    "print(f\"\\n{'─'*60}\")\n",
    "print(\"Class distribution (natural, no resampling):\")\n",
    "class_counts = manifest[\"intent_name\"].value_counts()\n",
    "for name, count in class_counts.items():\n",
    "    pct = 100.0 * count / len(manifest)\n",
    "    print(f\"  {name:25s}  {count:6d}  ({pct:5.1f}%)\")\n",
    "\n",
    "# ── Per-dataset breakdown ─────────────────────────────────────\n",
    "print(f\"\\nPer-dataset breakdown:\")\n",
    "cross = pd.crosstab(manifest[\"dataset\"], manifest[\"intent_name\"], margins=True)\n",
    "print(cross.to_string())\n",
    "\n",
    "print(f\"\\n{'━'*60}\")\n",
    "print(f\"Final manifest size: {len(manifest)} windows\")\n",
    "print(f\"{'━'*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c9cd14",
   "metadata": {},
   "source": [
    "## Stage 7 · Persist Outputs\n",
    "\n",
    "Save:\n",
    "- **`windows.npy`** — stacked `(N, 32000)` float32 array of all windows\n",
    "- **`manifest.csv`** — full metadata manifest\n",
    "- **`pipeline_config.json`** — frozen configuration for reproducibility\n",
    "\n",
    "On Kaggle the output goes to `/kaggle/working/processed/`.\n",
    "Locally it goes to `./processed_data/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e09987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# Stage 7 · Save Outputs\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "\n",
    "OUTPUT_DIR = Path(\"/kaggle/working/processed\") if IS_KAGGLE else Path(\"processed_data\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ── 1. Stack audio windows into a single (N, 32000) array ────\n",
    "X = np.stack(surviving_windows, axis=0)          # (N, 32000) float32\n",
    "print(f\"Audio tensor shape : {X.shape}  dtype: {X.dtype}\")\n",
    "print(f\"Audio tensor size  : {X.nbytes / 1e6:.1f} MB\")\n",
    "\n",
    "npy_path = OUTPUT_DIR / \"windows.npy\"\n",
    "np.save(npy_path, X)\n",
    "print(f\"Saved: {npy_path}\")\n",
    "\n",
    "# ── 2. Save manifest CSV ─────────────────────────────────────\n",
    "csv_path = OUTPUT_DIR / \"manifest.csv\"\n",
    "manifest.to_csv(csv_path, index=False)\n",
    "print(f\"Saved: {csv_path}\")\n",
    "\n",
    "# ── 3. Save frozen pipeline configuration ────────────────────\n",
    "config_snapshot = {\n",
    "    \"audio_contract\": asdict(AC),\n",
    "    \"intent_labels\": INTENT_NAMES,\n",
    "    \"global_seed\": GLOBAL_SEED,\n",
    "    \"ravdess_emotion_map\": {k: (v.name if v is not None else \"DROP\")\n",
    "                            for k, v in RAVDESS_EMOTION_MAP.items()},\n",
    "    \"threat_folder_intents\": {k: v.name for k, v in THREAT_FOLDER_INTENTS.items()},\n",
    "    \"audit_per_dataset\": audit,\n",
    "    \"final_manifest_rows\": len(manifest),\n",
    "    \"duplicates_removed\": n_dups,\n",
    "}\n",
    "\n",
    "config_path = OUTPUT_DIR / \"pipeline_config.json\"\n",
    "with open(config_path, \"w\") as f:\n",
    "    json.dump(config_snapshot, f, indent=2, default=str)\n",
    "print(f\"Saved: {config_path}\")\n",
    "\n",
    "print(f\"\\n✅ All outputs saved to {OUTPUT_DIR}/\")\n",
    "print(f\"   windows.npy           — {X.shape[0]} windows × {X.shape[1]} samples\")\n",
    "print(f\"   manifest.csv          — {len(manifest)} rows\")\n",
    "print(f\"   pipeline_config.json  — frozen config + audit trail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a571d4ca",
   "metadata": {},
   "source": [
    "## Stage 8 · Verification & Integrity Assertions\n",
    "\n",
    "Automated checks that MUST pass before this dataset can be used for training:\n",
    "\n",
    "| Check | Description |\n",
    "|-------|-------------|\n",
    "| **Shape** | Every row in `windows.npy` has exactly 32 000 samples |\n",
    "| **Dtype** | All audio is float32 |\n",
    "| **Range** | All values in [−1.0, +1.0] |\n",
    "| **Labels** | All `intent` values ∈ {0, 1, 2, 3} |\n",
    "| **Uniqueness** | No duplicate `window_id` or `sha256` |\n",
    "| **Manifest ↔ Array** | Row count matches between CSV and .npy |\n",
    "| **Round-trip** | Reload from disk and compare |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4645f934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# Stage 8 · Verification & Integrity Assertions\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "\n",
    "def verify_dataset(output_dir: Path, ac: AudioContract = AC) -> None:\n",
    "    \"\"\"Run all integrity checks. Raises AssertionError on any failure.\"\"\"\n",
    "\n",
    "    print(\"Running verification checks …\\n\")\n",
    "\n",
    "    # ── Reload from disk ──────────────────────────────────────\n",
    "    X_disk = np.load(output_dir / \"windows.npy\")\n",
    "    m_disk = pd.read_csv(output_dir / \"manifest.csv\")\n",
    "\n",
    "    # Check 1: manifest ↔ array row count\n",
    "    assert X_disk.shape[0] == len(m_disk), \\\n",
    "        f\"FAIL: array rows ({X_disk.shape[0]}) ≠ manifest rows ({len(m_disk)})\"\n",
    "    print(f\"  ✓ Manifest rows ({len(m_disk)}) == array rows ({X_disk.shape[0]})\")\n",
    "\n",
    "    # Check 2: window sample count\n",
    "    assert X_disk.shape[1] == ac.window_samples, \\\n",
    "        f\"FAIL: sample dim ({X_disk.shape[1]}) ≠ expected ({ac.window_samples})\"\n",
    "    print(f\"  ✓ Window length = {ac.window_samples} samples ({ac.window_sec}s)\")\n",
    "\n",
    "    # Check 3: dtype\n",
    "    assert X_disk.dtype == np.float32, f\"FAIL: dtype is {X_disk.dtype}\"\n",
    "    print(f\"  ✓ Dtype = float32\")\n",
    "\n",
    "    # Check 4: value range\n",
    "    assert float(np.min(X_disk)) >= -1.0, \"FAIL: values below −1.0\"\n",
    "    assert float(np.max(X_disk)) <=  1.0, \"FAIL: values above +1.0\"\n",
    "    print(f\"  ✓ Value range [{np.min(X_disk):.4f}, {np.max(X_disk):.4f}] ⊂ [−1, +1]\")\n",
    "\n",
    "    # Check 5: labels are valid\n",
    "    valid_intents = set(INTENT_NAMES.keys())\n",
    "    actual_intents = set(m_disk[\"intent\"].unique())\n",
    "    assert actual_intents.issubset(valid_intents), \\\n",
    "        f\"FAIL: invalid intents {actual_intents - valid_intents}\"\n",
    "    print(f\"  ✓ All intent labels valid: {sorted(actual_intents)}\")\n",
    "\n",
    "    # Check 6: unique window IDs\n",
    "    assert m_disk[\"window_id\"].is_unique, \"FAIL: duplicate window_id\"\n",
    "    print(f\"  ✓ All window_id values unique\")\n",
    "\n",
    "    # Check 7: unique SHA-256\n",
    "    assert m_disk[\"sha256\"].is_unique, \"FAIL: duplicate sha256\"\n",
    "    print(f\"  ✓ All SHA-256 hashes unique (no duplicate audio content)\")\n",
    "\n",
    "    # Check 8: no NaN in manifest\n",
    "    nan_count = int(m_disk.isna().sum().sum())\n",
    "    assert nan_count == 0, f\"FAIL: {nan_count} NaN values in manifest\"\n",
    "    print(f\"  ✓ No NaN values in manifest\")\n",
    "\n",
    "    # ── Summary ───────────────────────────────────────────────\n",
    "    print(f\"\\n{'━'*60}\")\n",
    "    print(f\"✅  ALL {8} VERIFICATION CHECKS PASSED\")\n",
    "    print(f\"    Dataset is ready for downstream training.\")\n",
    "    print(f\"{'━'*60}\")\n",
    "\n",
    "\n",
    "verify_dataset(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7dd166",
   "metadata": {},
   "source": [
    "## Stage 9 · Dataset Summary & Quick EDA\n",
    "\n",
    "Quick visual / tabular inspection of the final processed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd31f1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# Stage 9 · Quick EDA on final processed dataset\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")           # headless-safe backend\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# ── 1. Class distribution bar chart ──────────────────────────\n",
    "intent_counts = manifest[\"intent_name\"].value_counts()\n",
    "colors = [\"#2ecc71\", \"#e67e22\", \"#e74c3c\", \"#8e44ad\"]\n",
    "intent_counts.plot.bar(ax=axes[0], color=colors[:len(intent_counts)])\n",
    "axes[0].set_title(\"Class Distribution (natural)\")\n",
    "axes[0].set_ylabel(\"Window count\")\n",
    "axes[0].tick_params(axis=\"x\", rotation=30)\n",
    "\n",
    "# ── 2. Per-dataset contribution ──────────────────────────────\n",
    "dataset_counts = manifest[\"dataset\"].value_counts()\n",
    "dataset_counts.plot.bar(ax=axes[1], color=\"steelblue\")\n",
    "axes[1].set_title(\"Windows per Dataset Source\")\n",
    "axes[1].set_ylabel(\"Window count\")\n",
    "axes[1].tick_params(axis=\"x\", rotation=30)\n",
    "\n",
    "# ── 3. RMS distribution (quality check) ─────────────────────\n",
    "axes[2].hist(manifest[\"rms\"], bins=80, color=\"gray\", edgecolor=\"white\")\n",
    "axes[2].axvline(AC.rms_floor, color=\"red\", ls=\"--\", label=f\"silence floor ({AC.rms_floor})\")\n",
    "axes[2].set_title(\"Per-Window RMS Distribution\")\n",
    "axes[2].set_xlabel(\"RMS\")\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTPUT_DIR / \"eda_summary.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# ── Manifest sample ──────────────────────────────────────────\n",
    "print(\"\\nManifest sample (first 10 rows):\")\n",
    "print(manifest.head(10).to_string(index=False))\n",
    "\n",
    "# ── Full audit trail ─────────────────────────────────────────\n",
    "print(f\"\\n{'─'*60}\")\n",
    "print(\"AUDIT TRAIL (per-dataset)\")\n",
    "for ds_name, stats in audit.items():\n",
    "    print(f\"\\n  {ds_name}:\")\n",
    "    for k, v in stats.items():\n",
    "        print(f\"    {k:20s}: {v}\")\n",
    "\n",
    "print(f\"\\n{'━'*60}\")\n",
    "print(\"Pipeline complete. Dataset is ready for model training.\")\n",
    "print(f\"{'━'*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv-tinyml)",
   "language": "python",
   "name": "venv-tinyml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
