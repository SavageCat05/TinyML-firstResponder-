# ðŸ§  TinyML Emergency Detection: v1.1 Architecture Blueprint

## ðŸ—ï¸ Model Overview

The model is a **MobileNetV2-inspired Inverted Residual Network** optimized for 16-bit or 8-bit quantization. It replaces the heavy  math of standard convolutions with  depthwise separable operations.

### ðŸ“ Layer-by-Layer Specification

| Layer | Type | Configuration | Purpose |
| --- | --- | --- | --- |
| **Input** | `Input` | (40, 50, 1) | Log-Mel Spectrogram (40 bins, 50 frames). |
| **Stem** | `Conv2D` | 16 filters, 3x3, Stride 2 | Rapidly downsample high-res audio features. |
| **Block 1** | `InvertedResidual` | Expansion: 2x, Filters: 24 | Captures low-level harmonic structures. |
| **Block 2** | `InvertedResidual` | Expansion: 4x, Filters: 32, SE | Focuses on mid-range "distress" frequencies. |
| **Block 3** | `InvertedResidual` | Expansion: 4x, Filters: 64, SE | Distinguishes between similar sirens. |
| **Attention** | `Squeeze-Excite` | Ratio: 4 | Dynamically suppresses background noise. |
| **Pooling** | `GlobalMaxPool` | - | Ensures 0.2s "spikes" aren't averaged out. |
| **Head** | `Dense` | 64 units, Dropout 0.3 | Feature projection with regularization. |
| **Output** | `Softmax` | 6 Units | Probability distribution across 6 classes. |

---

## ðŸ› ï¸ Critical Components for the AI Agent

### 1. The Inverted Residual (MBConv) Block

The AI should implement the block with a **Linear Bottleneck** to prevent information loss during the compression phase.

### 2. Squeeze-and-Excitation (SE) Logic

The SE block must follow the "Global Average Pool -> Reduce -> Expand -> Sigmoid" pattern. This allows the model to learn which Mel-bins (frequency channels) are noise and which are emergency signals.

### 3. Mathematical Optimization (Depthwise Separation)

Standard Conv2D math is replaced to save memory:

* **Step 1:**  Depthwise Convolution (Spatial filtering).
* **Step 2:**  Pointwise Convolution (Channel mixing).

---

## ðŸ“‹ Implementation Guidelines for AI Agent

* **Normalization**: Apply `BatchNormalization` after every convolution layer before the activation.
* **Activation**: Use `ReLU6` instead of standard `ReLU`. It is more stable on low-power hardware and prevents activations from "exploding" during fixed-point quantization.
* **Quantization-Aware Training (Optional)**: If targeting ultra-low power (Cortex-M0), the agent should use the `tensorflow_model_optimization` toolkit to simulate quantization during training.
* **Buffer Strategy**: Ensure the sliding window logic in `audio_capture.py` matches the 50-frame temporal width of the input layer.
